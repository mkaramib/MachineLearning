{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "QuestionClassifier.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNUYAgPG+4lLCpRAzxBkCYS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mkaramib/MachineLearning/blob/main/QuestionClassifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pT5D9NVs7jp9"
      },
      "source": [
        "## Question Classification\r\n",
        "In this notebook, I will implement a question classifier using Trax deep learning framework. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykH9bNfx7iBh"
      },
      "source": [
        "import numpy as np\r\n",
        "import nltk\r\n",
        "from nltk.tokenize import word_tokenize\r\n",
        "from unicodedata import normalize\r\n",
        "import re\r\n",
        "from nltk.corpus import stopwords\r\n",
        "from sklearn.neural_network import MLPClassifier\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.svm import LinearSVC, SVC\r\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5eksliVNmrs"
      },
      "source": [
        "# Download required packages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJcOW6d4NknG",
        "outputId": "380b920d-6167-476a-9712-89158e4674c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "nltk.download('punkt')\r\n",
        "nltk.download('stopwords')\r\n",
        "stop_words = set(stopwords.words('english'))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hctu-A1i78ib"
      },
      "source": [
        "## Data Import\r\n",
        "In this section, all the training and testing questions are read.\r\n",
        "\r\n",
        "\r\n",
        "*   Train Data: contains 1000/2000/3000 questions in each file.\r\n",
        "*   Test Data: contains close to 500 questions to evaluate the trained model.\r\n",
        "\r\n",
        "# Question format\r\n",
        "In each file(train and test), each line contains a question which has the following format:\r\n",
        "\r\n",
        "\r\n",
        "> QuestionCategory: Question content.\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEcuq28JOcw_"
      },
      "source": [
        "# Tokenize function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGTsv-QeOa3c"
      },
      "source": [
        "def tokenize(question):\r\n",
        "    \"\"\"\r\n",
        "    separate the question type as well as question tokens\r\n",
        "    :param question:\r\n",
        "    :return:\r\n",
        "    \"\"\"\r\n",
        "    # index of colon\r\n",
        "    colon = question.find(':')\r\n",
        "\r\n",
        "    # get question type\r\n",
        "    q_cat = question[0:colon]\r\n",
        "    content_normalized = normalize('NFKC', question[colon:])\r\n",
        "    content_normalized = re.sub(\"[^a-zA-Z. ]\", \"\", content_normalized)\r\n",
        "    terms_all = word_tokenize(content_normalized)\r\n",
        "\r\n",
        "    # remove the stop words\r\n",
        "    terms = [w for w in terms_all if not w in stop_words]\r\n",
        "    #terms = terms_all\r\n",
        "    return q_cat, terms"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Uuk7-J4Osd2"
      },
      "source": [
        "# Load and preprocess questions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGoi2Y5fOyH9"
      },
      "source": [
        "def read_questions(file):\r\n",
        "    \"\"\"\r\n",
        "    read questions from file and tokenize them\r\n",
        "    :param file:\r\n",
        "    :return: list of (question category, question tokens)\r\n",
        "    \"\"\"\r\n",
        "    f = open(file, 'r', encoding=\"ISO-8859-1\")\r\n",
        "    lines = f.readlines()\r\n",
        "\r\n",
        "    questions = []\r\n",
        "    for line in lines:\r\n",
        "        cat, terms = tokenize(line)\r\n",
        "        questions.append((cat, terms))\r\n",
        "\r\n",
        "    return questions"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Lz75Qm5QXpr"
      },
      "source": [
        "# Build TF Training matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkwX8tP9Qle8"
      },
      "source": [
        "def build_tfidf_train_matrix(questions, stopword=False):\r\n",
        "    \"\"\"\r\n",
        "    build the tf.idf training matrix \r\n",
        "    :param questions: \r\n",
        "    :param stopword: use stop word or not\r\n",
        "    :return: X:2D array , Y: output\r\n",
        "    \"\"\"\r\n",
        "    cats = [cat for (cat, q) in questions]\r\n",
        "    unique_cats = list(set(cats))\r\n",
        "    f_set = set()\r\n",
        "    m = len(cats)   # length of questions\r\n",
        "\r\n",
        "    # generate the feature sets\r\n",
        "    for (cat, terms) in questions:\r\n",
        "        f_set.update(terms)\r\n",
        "\r\n",
        "    # convert set to list to have indexes\r\n",
        "    f_set = list(f_set)\r\n",
        "\r\n",
        "    # build the Y\r\n",
        "    Y = [unique_cats.index(cat) for cat in cats]\r\n",
        "\r\n",
        "    # build the X\r\n",
        "    X = np.zeros((m, len(f_set)))\r\n",
        "    for i in range(m):\r\n",
        "        terms = questions[i][1]\r\n",
        "        for t in terms:\r\n",
        "            X[i, f_set.index(t)] += 1\r\n",
        "\r\n",
        "    # calc the DF(document frequency) of terms\r\n",
        "    DF = np.count_nonzero(X, axis=0)\r\n",
        "    IDF = np.log((m+1)/(DF+1)) + 1\r\n",
        "\r\n",
        "    # update the X, multiply tf into IDF\r\n",
        "    for i in range(len(f_set)):\r\n",
        "        X[:,i] = X[:,i] * IDF[i]\r\n",
        "\r\n",
        "    return X, Y, f_set, unique_cats"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IATDVSMXQnDi"
      },
      "source": [
        "# Build TF test matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqEM1HjnQw1h"
      },
      "source": [
        "def build_tfidf_test_matrix(questions, features, cats, stopword=False):\r\n",
        "    \"\"\"\r\n",
        "    build the tf.idf training matrix\r\n",
        "    :param questions:\r\n",
        "    :param stopword: use stop word or not\r\n",
        "    :return: X:2D array , Y: output\r\n",
        "    \"\"\"\r\n",
        "    # len of test samples\r\n",
        "    m = len(questions)\r\n",
        "\r\n",
        "    # build the Y\r\n",
        "    Y = []\r\n",
        "\r\n",
        "    # build the X\r\n",
        "    X = np.zeros((m, len(features)))\r\n",
        "    for i in range(m):\r\n",
        "        Y.append(cats.index(questions[i][0]))\r\n",
        "        terms = questions[i][1]\r\n",
        "        for t in terms:\r\n",
        "            if t in features:\r\n",
        "                X[i, features.index(t)] += 1\r\n",
        "\r\n",
        "    # calc the DF(document frequency) of terms\r\n",
        "    DF = np.count_nonzero(X, axis=0)\r\n",
        "    IDF = np.log((m+1)/(DF+1)) + 1\r\n",
        "\r\n",
        "    # update the X, multiply tf into IDF\r\n",
        "    for i in range(len(features)):\r\n",
        "        X[:,i] = X[:,i] * IDF[i]\r\n",
        "\r\n",
        "    return X, Y"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAKybT7pQx_I"
      },
      "source": [
        "# Scikit-learn Classifier functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0D3qzLM0RAs6"
      },
      "source": [
        "def mlp(X_train, Y_train, X_test, Y_test, d_input, d_output):\r\n",
        "    NN = MLPClassifier(solver='lbfgs', alpha=0.01, hidden_layer_sizes=(d_input, d_output), random_state=1)\r\n",
        "    NN.fit(X_train, Y_train)\r\n",
        "    print(f\"Sklearn Neural Network - train performance = {round(NN.score(X_train, Y_train), 4)}\")\r\n",
        "    print(f\"Sklearn Neural Network - test performance = {round(NN.score(X_test, Y_test), 4)}\")\r\n",
        "\r\n",
        "\r\n",
        "def logistic_regression(X_train, Y_train, X_test, Y_test):\r\n",
        "    # run logistic regression\r\n",
        "    LR = LogisticRegression(random_state=0, solver='lbfgs', multi_class='ovr').fit(X_train, Y_train)\r\n",
        "    print(f\"Logistic Regression - train performance = {round(LR.score(X_train, Y_train), 4)}\")\r\n",
        "    print(f\"Logistic Regression - test performance = {round(LR.score(X_test, Y_test), 4)}\")\r\n",
        "\r\n",
        "\r\n",
        "def svm(X_train, Y_train, X_test, Y_test):\r\n",
        "    # run SVM\r\n",
        "    #SVM = LinearSVC()\r\n",
        "    SVM = SVC(decision_function_shape='ovo')\r\n",
        "    SVM.fit(X_train, Y_train)\r\n",
        "    print(f\"SVM - train performance = {round(SVM.score(X_train, Y_train), 4)}\")\r\n",
        "    print(f\"SVM - test performance = {round(SVM.score(X_test, Y_test), 4)}\")\r\n",
        "\r\n",
        "\r\n",
        "def random_forest(X_train, Y_train, X_test, Y_test):\r\n",
        "    # run random forest\r\n",
        "    RF = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0)\r\n",
        "    RF.fit(X_train, Y_train)\r\n",
        "    print(f\"Random Forest - train performance = {round(RF.score(X_train, Y_train), 4)}\")\r\n",
        "    print(f\"Random Forest - test performance = {round(RF.score(X_test, Y_test), 4)}\")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npzqrvjPRCc0"
      },
      "source": [
        "# Run the Scikit_learn classifiers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9D-cNA2DRI2m"
      },
      "source": [
        "def run_sklearns(train, test):\r\n",
        "    X_train, Y_train, features, cats = build_tfidf_train_matrix(train)\r\n",
        "    X_test, Y_test = build_tfidf_test_matrix(test, features,cats,False)\r\n",
        "\r\n",
        "    # run logistic regression\r\n",
        "    #logistic_regression(X_train, Y_train, X_test, Y_test)\r\n",
        "\r\n",
        "    # run svm\r\n",
        "    #svm(X_train, Y_train, X_test, Y_test)\r\n",
        "\r\n",
        "    # run random forest\r\n",
        "    #random_forest(X_train, Y_train, X_test, Y_test)\r\n",
        "\r\n",
        "    # run mlp\r\n",
        "    mlp(X_train, Y_train, X_test, Y_test, len(features), len(cats))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4Mj5Q-pRMLB"
      },
      "source": [
        "## Main part to load, train, and run classifiers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9vQvC3JRZk6"
      },
      "source": [
        "# read the questions\r\n",
        "train_qs = read_questions(\"./questions/train_5500.label\")\r\n",
        "test_qs = read_questions(\"./questions/TREC_10.label\")\r\n",
        "\r\n",
        "# run the MlP classifier\r\n",
        "run_sklearns(train_qs, test_qs)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
